{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaigilat/exploring-tabpfn/blob/main/explore_tabpfn_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33328c77"
      },
      "source": [
        "# Deep Dive into TabPFN's Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80b8a09"
      },
      "source": [
        "This notebook aims to demystify the internal preprocessing steps of TabPFN (Tabular Neural Network) by breaking down its `_initialize_dataset_preprocessing` method. We will walk through each transformation applied to the raw data, from validation and type fixing to categorical encoding, scaling, and feature shuffling, and observe how each step alters the dataset before it is fed into the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpMQEzLo7HsR",
        "outputId": "edcff5c1-f589-474b-8a4f-647ac6c23742",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/551.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m542.7/551.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m551.9/551.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting shapiq\n",
            "  Downloading shapiq-1.4.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shapiq) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shapiq) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shapiq) (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from shapiq) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shapiq) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from shapiq) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from shapiq) (2.32.5)\n",
            "Collecting sparse-transform (from shapiq)\n",
            "  Downloading sparse_transform-0.2.1-py3-none-any.whl.metadata (759 bytes)\n",
            "Collecting galois (from shapiq)\n",
            "  Downloading galois-0.4.10-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from shapiq) (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from shapiq) (3.6.1)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.12/dist-packages (from shapiq) (0.1.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from shapiq) (11.3.0)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.12/dist-packages (from galois->shapiq) (0.60.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from galois->shapiq) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->shapiq) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shapiq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shapiq) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->shapiq) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->shapiq) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->shapiq) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->shapiq) (2025.11.12)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shapiq) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55->galois->shapiq) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->shapiq) (1.17.0)\n",
            "Downloading shapiq-1.4.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading galois-0.4.10-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sparse_transform-0.2.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: galois, sparse-transform, shapiq\n",
            "Successfully installed galois-0.4.10 shapiq-1.4.1 sparse-transform-0.2.1\n",
            "✅ Installation complete. Ready to inspect TabPFN v2.\n"
          ]
        }
      ],
      "source": [
        "# @title Installation & Setup\n",
        "# Install the official TabPFN package\n",
        "!pip install tabpfn==6.0.6 -q\n",
        "!pip install shapiq\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shapiq\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Import TabPFN components\n",
        "from tabpfn import TabPFNClassifier\n",
        "from tabpfn.constants import ModelVersion\n",
        "# Import the specific internal utility functions TabPFN uses\n",
        "from tabpfn.utils import (\n",
        "    validate_Xy_fit,\n",
        "    infer_categorical_features,\n",
        "    fix_dtypes,\n",
        "    process_text_na_dataframe\n",
        ")\n",
        "from tabpfn.preprocessors.preprocessing_helpers import get_ordinal_encoder\n",
        "\n",
        "# Set print options for cleaner output\n",
        "torch.set_printoptions(sci_mode=False, precision=4, linewidth=120)\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "\n",
        "print(\"✅ Installation complete. Ready to inspect TabPFN v2.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dee021e3"
      },
      "source": [
        "## Step 0. Dataset Description: Titanic Survival Prediction\n",
        "\n",
        "For this deep dive, we'll use the classic Titanic dataset, which contains information about passengers on the ill-fated RMS Titanic. The goal is to predict survival based on features like passenger class, sex, age, and embarkation point.\n",
        "\n",
        "| Feature Name | Type    | NaNs | Description                                     |\n",
        "|--------------|---------|------|-------------------------------------------------|\n",
        "| `Pclass`     | int64   | 0    | Passenger Class (1st, 2nd, 3rd)                 |\n",
        "| `Sex`        | object  | 0    | Gender (male, female)                           |\n",
        "| `Age`        | float64 | 177  | Age in years                                    |\n",
        "| `SibSp`      | int64   | 0    | Number of siblings/spouses aboard               |\n",
        "| `Parch`      | int64   | 0    | Number of parents/children aboard               |\n",
        "| `Fare`       | float64 | 0    | Passenger fare                                  |\n",
        "| `Embarked`   | object  | 2    | Port of Embarkation (C, Q, S)                   |\n",
        "| `Ticket`     | object  | 0    | Ticket number                                   |\n",
        "| `Name`       | object  | 0    | Passenger's name                                |\n",
        "| `Cabin`      | object  | 687  | Cabin number                                    |\n",
        "\n",
        "**Target Variable:**\n",
        "- `Survived`: Survival status (0 = No, 1 = Yes)\n",
        "\n",
        "This dataset is ideal for demonstrating TabPFN's preprocessing due to its mix of numerical, categorical, and missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474,
          "referenced_widgets": [
            "0957dadd37824a0f9b9adf623e72c505",
            "363b55b04f184a02aa5e8e3b5b01abd0",
            "877ff8b187ba48538cb881aa0b00039b",
            "4f64dda473ec4303b6f5025164cdb9a4",
            "be29304e7da547f9b7c38eab1df3e07b",
            "311f2e6e9c1e4ecb858c3fe80b778153",
            "484872c0132c4cb58fbea0d3756f8464",
            "9da5a8773e0243e287005b9ae37e16af",
            "f787781975464c40b60ca250cab3a416",
            "a10c62c1a2bf4691bcc651b07386b32c",
            "2681578b0f7b4b97b4b56298d544a5a3",
            "2ab1b780b8b546ef8a110cbb00af71a7",
            "29048f9d63344e51b60d94e8db67fdf0",
            "621d9ccff5d6484f9170b97395f68df9",
            "f4c646118a3944c3a5d09a5aaea0f965",
            "5e3953ee49fc43ed85a6b77ef52844fa",
            "badbbe9d88b942bd9263bfbb7fa527c3",
            "a157b69dd96a4728918e38feeaa77fb9",
            "7a6bfbc483974cc0816b3ec46fc166c0",
            "7af7bb1d02df42e89a9bdce10a8baa1c",
            "60623e4ce60e4b6eaa555650ff4b8d90",
            "9baf3a28031c4c47bd77f0fe88e1f24c"
          ]
        },
        "id": "49bdf7a2",
        "outputId": "8a080bd2-a0e6-4581-b559-00cffbc661fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
            "\n",
            "Dataset Preview (Training Data):\n",
            "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked      Ticket                               Name Cabin\n",
            "86        3    male  16.0      1      3  34.3750        S  W./C. 6608             Ford, Mr. William Neal   NaN\n",
            "329       1  female  16.0      0      1  57.9792        C      111361       Hippach, Miss. Jean Gertrude   B18\n",
            "517       3    male   NaN      0      0  24.1500        Q      371110                  Ryan, Mr. Patrick   NaN\n",
            "844       3    male  17.0      0      0   8.6625        S      315090                Culumovic, Mr. Jeso   NaN\n",
            "408       3    male  21.0      0      0   7.7750        S      312992  Birkeland, Mr. Hans Martin Monsen   NaN\n",
            "\n",
            "Original Shape: (891, 12)\n",
            "Training Data Shape: (801, 10)\n",
            "Testing Data Shape: (90, 10)\n",
            "Percentage Survived in Train Data: 38.3%%\n",
            "Percentage Survived in Test Data: 38.9%%\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tabpfn-v2-classifier-finetuned-zk73skhh.(…):   0%|          | 0.00/29.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0957dadd37824a0f9b9adf623e72c505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab1b780b8b546ef8a110cbb00af71a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabPFNClassifier(device='cpu',\n",
              "                 model_path='/root/.cache/tabpfn/tabpfn-v2-classifier-finetuned-zk73skhh.ckpt',\n",
              "                 n_estimators=4)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier(device=&#x27;cpu&#x27;,\n",
              "                 model_path=&#x27;/root/.cache/tabpfn/tabpfn-v2-classifier-finetuned-zk73skhh.ckpt&#x27;,\n",
              "                 n_estimators=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TabPFNClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNClassifier(device=&#x27;cpu&#x27;,\n",
              "                 model_path=&#x27;/root/.cache/tabpfn/tabpfn-v2-classifier-finetuned-zk73skhh.ckpt&#x27;,\n",
              "                 n_estimators=4)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# @title Raw Data Loading\n",
        "import pandas as pd # Import pandas to resolve NameError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "print(f\"Loading dataset from: {url}\")\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Select a mix of features to match your requirements:\n",
        "# Select a mix of features (Numeric, Categorical, some with NaNs)\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Ticket', 'Name', 'Cabin']\n",
        "target = 'Survived'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_raw, X_test, y_raw, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "print(\"\\nDataset Preview (Training Data):\")\n",
        "print(X_raw.head().to_string())\n",
        "print(f\"\\nOriginal Shape: {df.shape}\")\n",
        "print(f\"Training Data Shape: {X_raw.shape}\")\n",
        "print(f\"Testing Data Shape: {X_test.shape}\")\n",
        "# Calculate and print the percentage of survived in the test data\n",
        "print(f\"Percentage Survived in Train Data: {y_raw.sum() / len(y_raw):.1%}%\")\n",
        "print(f\"Percentage Survived in Test Data: {y_test.sum() / len(y_test):.1%}%\")\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "clf = TabPFNClassifier.create_default_for_version(\n",
        "    ModelVersion.V2,\n",
        "    device='cpu',\n",
        "    n_estimators=4\n",
        ")\n",
        "# Fit on a small subset of the training data to initialize the model\n",
        "clf.fit(X_raw.iloc[:50], y_raw.iloc[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e7e222"
      },
      "source": [
        "## Step 1. Inital Preprocessing: breaking down  `_initialize_dataset_preprocessing`\n",
        "\n",
        "TabPFN's `_initialize_dataset_preprocessing` method orchestrates the initial data preparation, setting up the foundation for all subsequent ensemble views. It performs several crucial steps:\n",
        "\n",
        "1.  **Validation & Cleaning:** Ensures data integrity by checking for disallowed types, infinities, and basic structural requirements.\n",
        "2.  **Target (Label) Encoding:** Transforms the target variable into a numerical format (0 to N-1 classes).\n",
        "3.  **Categorical Inference & Type Fixing:** Identifies categorical features (if not provided) and casts them to a 'category' dtype, also handling object types.\n",
        "4.  **Ordinal Encoding & String Vectorization:** Converts categorical and string columns into numerical representations suitable for the model, including handling missing string values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lYd_-twmbV2",
        "outputId": "18050342-05e6-48a9-b71d-fdc86e258a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw Dataset\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "            Dtype  Null Count  Null %\n",
            "Pclass      int64           0    0.00\n",
            "Sex        object           0    0.00\n",
            "Age       float64         161   20.10\n",
            "SibSp       int64           0    0.00\n",
            "Parch       int64           0    0.00\n",
            "Fare      float64           0    0.00\n",
            "Embarked   object           2    0.25\n",
            "Ticket     object           0    0.00\n",
            "Name       object           0    0.00\n",
            "Cabin      object         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked      Ticket                               Name Cabin\n",
            "86        3    male  16.0      1      3  34.3750        S  W./C. 6608             Ford, Mr. William Neal   NaN\n",
            "329       1  female  16.0      0      1  57.9792        C      111361       Hippach, Miss. Jean Gertrude   B18\n",
            "517       3    male   NaN      0      0  24.1500        Q      371110                  Ryan, Mr. Patrick   NaN\n",
            "844       3    male  17.0      0      0   8.6625        S      315090                Culumovic, Mr. Jeso   NaN\n",
            "408       3    male  21.0      0      0   7.7750        S      312992  Birkeland, Mr. Hans Martin Monsen   NaN\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# @title Step 1.0: Show Raw Data\n",
        "\n",
        "def display_dataset_state(df, title, additional_info=None):\n",
        "    \"\"\"\n",
        "    Displays the head, shape, null counts, and dtypes of a DataFrame.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{title}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Ensure df is a pandas DataFrame for consistent handling\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "        df = pd.DataFrame(df)\n",
        "\n",
        "    # 1. Basic Shape\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "\n",
        "    # 2. Nulls & Dtypes Summary\n",
        "    print(\"\\nColumn Summary:\")\n",
        "    summary = pd.DataFrame({\n",
        "        'Dtype': df.dtypes,\n",
        "        'Null Count': df.isnull().sum(),\n",
        "        'Null %': (df.isnull().sum() / len(df) * 100).round(2)\n",
        "    })\n",
        "    print(summary)\n",
        "\n",
        "    # 3. Head\n",
        "    print(\"\\nHead of DataFrame:\")\n",
        "    print(df.head().to_string())\n",
        "\n",
        "    # 4. Additional Info\n",
        "    if additional_info:\n",
        "        print(\"\\nAdditional Info:\")\n",
        "        for key, value in additional_info.items():\n",
        "            print(f\"- {key}: {value}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "display_dataset_state(X_raw, \"Raw Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c17ZMiKAQLL",
        "outputId": "b51c324a-0d65-4f89-b9bf-752ef3052a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Start Initial Dataset Preprocessing Steps ---\n",
            "==================================================\n",
            "\n",
            "--- Step 1.1: Validate dataset ---\n",
            "  Description: Checks for disallowed types, infinite values, and ensures basic structure.\n",
            "Maximum number of samples for inference: 10000\n",
            "Maximum number of features for inference: 500\n",
            "Ignore pretraining limits: False\n",
            "Status: Validation Successful (Data copied)\n",
            "\n",
            "Step 1.1 Output (After Validation)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "    Dtype  Null Count  Null %\n",
            "0  object           0    0.00\n",
            "1  object           0    0.00\n",
            "2  object         161   20.10\n",
            "3  object           0    0.00\n",
            "4  object           0    0.00\n",
            "5  object           0    0.00\n",
            "6  object           2    0.25\n",
            "7  object           0    0.00\n",
            "8  object           0    0.00\n",
            "9  object         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "   0       1     2  3  4        5  6           7                                  8    9\n",
            "0  3    male  16.0  1  3   34.375  S  W./C. 6608             Ford, Mr. William Neal  NaN\n",
            "1  1  female  16.0  0  1  57.9792  C      111361       Hippach, Miss. Jean Gertrude  B18\n",
            "2  3    male   NaN  0  0    24.15  Q      371110                  Ryan, Mr. Patrick  NaN\n",
            "3  3    male  17.0  0  0   8.6625  S      315090                Culumovic, Mr. Jeso  NaN\n",
            "4  3    male  21.0  0  0    7.775  S      312992  Birkeland, Mr. Hans Martin Monsen  NaN\n",
            "\n",
            "Additional Info:\n",
            "- Shape after validation: (801, 10)\n",
            "==================================================\n",
            "\n",
            "--- Step 1.2: Target encoding ---\n",
            "  Description: Converts target classes (e.g., 'Yes'/'No' or 0/1) into strict integers 0..N-1.\n",
            "y (After):  [0 1 0 0 0 0 0 1 0 1]\n",
            "Classes:    [0 1]\n",
            "\n",
            "Step 1.2 Output (X after target encoding)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "    Dtype  Null Count  Null %\n",
            "0  object           0    0.00\n",
            "1  object           0    0.00\n",
            "2  object         161   20.10\n",
            "3  object           0    0.00\n",
            "4  object           0    0.00\n",
            "5  object           0    0.00\n",
            "6  object           2    0.25\n",
            "7  object           0    0.00\n",
            "8  object           0    0.00\n",
            "9  object         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "   0       1     2  3  4        5  6           7                                  8    9\n",
            "0  3    male  16.0  1  3   34.375  S  W./C. 6608             Ford, Mr. William Neal  NaN\n",
            "1  1  female  16.0  0  1  57.9792  C      111361       Hippach, Miss. Jean Gertrude  B18\n",
            "2  3    male   NaN  0  0    24.15  Q      371110                  Ryan, Mr. Patrick  NaN\n",
            "3  3    male  17.0  0  0   8.6625  S      315090                Culumovic, Mr. Jeso  NaN\n",
            "4  3    male  21.0  0  0    7.775  S      312992  Birkeland, Mr. Hans Martin Monsen  NaN\n",
            "\n",
            "Additional Info:\n",
            "- y_encoded_head: [0 1 0 0 0]\n",
            "==================================================\n",
            "\n",
            "--- Step 1.3: Identify Categorical variables and Fix Data Types ---\n",
            "  Description: Guesses categorical columns and casts them to pandas 'category' dtype, also handling object types.\n",
            "Minimum number of samples required for categorical inference: 100\n",
            "Maximum number of unique values for a feature to be considered categorical: 30\n",
            "Minimum number of unique values for a feature to be considered numerical: 4\n",
            "\n",
            "Step 1.3 Output (After Fixing Dtypes)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "            Dtype  Null Count  Null %\n",
            "0        category           0    0.00\n",
            "1        category           0    0.00\n",
            "2         float64         161   20.10\n",
            "3         float64           0    0.00\n",
            "4         float64           0    0.00\n",
            "5         float64           0    0.00\n",
            "6  string[python]           2    0.25\n",
            "7  string[python]           0    0.00\n",
            "8  string[python]           0    0.00\n",
            "9  string[python]         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "   0       1     2    3    4        5  6           7                                  8     9\n",
            "0  3    male  16.0  1.0  3.0  34.3750  S  W./C. 6608             Ford, Mr. William Neal  <NA>\n",
            "1  1  female  16.0  0.0  1.0  57.9792  C      111361       Hippach, Miss. Jean Gertrude   B18\n",
            "2  3    male   NaN  0.0  0.0  24.1500  Q      371110                  Ryan, Mr. Patrick  <NA>\n",
            "3  3    male  17.0  0.0  0.0   8.6625  S      315090                Culumovic, Mr. Jeso  <NA>\n",
            "4  3    male  21.0  0.0  0.0   7.7750  S      312992  Birkeland, Mr. Hans Martin Monsen  <NA>\n",
            "\n",
            "Additional Info:\n",
            "- Inferred Categorical Indices: [0, 1]\n",
            "==================================================\n",
            "\n",
            "--- Step 1.4: Ordinal Encoding & Vectorization ---\n",
            "  Description: Converts categorical and string columns into numerical representations suitable for the model, including handling missing string values.\n",
            "\n",
            "Step 1.4 Output (After Ordinal Encoding)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "     Dtype  Null Count  Null %\n",
            "0  float64           0    0.00\n",
            "1  float64           0    0.00\n",
            "2  float64           0    0.00\n",
            "3  float64           0    0.00\n",
            "4  float64           0    0.00\n",
            "5  float64           0    0.00\n",
            "6  float64         163   20.35\n",
            "7  float64           0    0.00\n",
            "8  float64           0    0.00\n",
            "9  float64         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     0    1    2      3      4      5     6    7    8        9\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN\n",
            "==================================================\n",
            "Action: 'Sex' and 'Embarked' were ordinal encoded. String columns ('Ticket', 'Name', 'Cabin') were also vectorized.\n",
            "Action: Column order might have changed due to preprocessing.\n",
            "\n",
            "Combined Output from _initialize_dataset_preprocessing (for comparison)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "     Dtype  Null Count  Null %\n",
            "0  float64           0    0.00\n",
            "1  float64           0    0.00\n",
            "2  float64           0    0.00\n",
            "3  float64           0    0.00\n",
            "4  float64           0    0.00\n",
            "5  float64           0    0.00\n",
            "6  float64         163   20.35\n",
            "7  float64           0    0.00\n",
            "8  float64           0    0.00\n",
            "9  float64         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     0    1    2      3      4      5     6    7    8        9\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN\n",
            "==================================================\n",
            "==================================================\n",
            "--- End Initial Dataset Preprocessing Steps ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py:604: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
            "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
            "  check_cpu_warning(\n"
          ]
        }
      ],
      "source": [
        "# @title Steps 1.1-1.4: Run the full initial dataset preprocessing\n",
        "# We use the internal method to reproduce the preprocessing exactly\n",
        "# This returns the numpy array that TabPFN actually uses\n",
        "\n",
        "print(\"--- Start Initial Dataset Preprocessing Steps ---\")\n",
        "print(\"==================================================\")\n",
        "\n",
        "# --- Step 1.1: Validate dataset ---\n",
        "print(\"\\n--- Step 1.1: Validate dataset ---\")\n",
        "print(\"  Description: Checks for disallowed types, infinite values, and ensures basic structure.\")\n",
        "print(f\"Maximum number of samples for inference: {clf.inference_config_.MAX_NUMBER_OF_SAMPLES}\")\n",
        "print(f\"Maximum number of features for inference: {clf.inference_config_.MAX_NUMBER_OF_FEATURES}\")\n",
        "print(f\"Ignore pretraining limits: {clf.ignore_pretraining_limits}\")\n",
        "X_valid, y_valid, feature_names_in, n_features_in = validate_Xy_fit(\n",
        "            X_raw,\n",
        "            y_raw,\n",
        "            estimator=clf,\n",
        "            ensure_y_numeric=False,\n",
        "            max_num_samples=clf.inference_config_.MAX_NUMBER_OF_SAMPLES,\n",
        "            max_num_features=clf.inference_config_.MAX_NUMBER_OF_FEATURES,\n",
        "            ignore_pretraining_limits=clf.ignore_pretraining_limits,\n",
        "        )\n",
        "print(\"Status: Validation Successful (Data copied)\")\n",
        "display_dataset_state(X_valid, \"Step 1.1 Output (After Validation)\", additional_info={'Shape after validation': X_valid.shape})\n",
        "\n",
        "# --- Step 1.2: Target encoding ---\n",
        "print(\"\\n--- Step 1.2: Target encoding ---\")\n",
        "print(\"  Description: Converts target classes (e.g., 'Yes'/'No' or 0/1) into strict integers 0..N-1.\")\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_valid)\n",
        "# X_encoded is just X_valid copied at this stage for consistent variable naming\n",
        "X_encoded = X_valid.copy()\n",
        "print(f\"y (After):  {y_encoded[:10]}\")\n",
        "print(f\"Classes:    {label_encoder.classes_}\")\n",
        "display_dataset_state(pd.DataFrame(X_encoded), \"Step 1.2 Output (X after target encoding)\", additional_info={'y_encoded_head': y_encoded[:5]})\n",
        "\n",
        "# --- Step 1.3: Identify Categorical variables and Fix Data Types ---\n",
        "print(\"\\n--- Step 1.3: Identify Categorical variables and Fix Data Types ---\")\n",
        "print(\"  Description: Guesses categorical columns and casts them to pandas 'category' dtype, also handling object types.\")\n",
        "print(f\"Minimum number of samples required for categorical inference: {clf.inference_config_.MIN_NUMBER_SAMPLES_FOR_CATEGORICAL_INFERENCE}\")\n",
        "print(f\"Maximum number of unique values for a feature to be considered categorical: {clf.inference_config_.MAX_UNIQUE_FOR_CATEGORICAL_FEATURES}\")\n",
        "print(f\"Minimum number of unique values for a feature to be considered numerical: {clf.inference_config_.MIN_UNIQUE_FOR_NUMERICAL_FEATURES}\")\n",
        "cat_indices = infer_categorical_features(\n",
        "    X_encoded,\n",
        "    provided=clf.categorical_features_indices,\n",
        "    min_samples_for_inference=clf.inference_config_.MIN_NUMBER_SAMPLES_FOR_CATEGORICAL_INFERENCE,\n",
        "    max_unique_for_category=clf.inference_config_.MAX_UNIQUE_FOR_CATEGORICAL_FEATURES,\n",
        "    min_unique_for_numerical=clf.inference_config_.MIN_UNIQUE_FOR_NUMERICAL_FEATURES,\n",
        ")\n",
        "X_fixed_dtypes = fix_dtypes(X_encoded, cat_indices=cat_indices)\n",
        "y_fixed_dtypes = y_encoded.copy()\n",
        "display_dataset_state(X_fixed_dtypes, \"Step 1.3 Output (After Fixing Dtypes)\", additional_info={'Inferred Categorical Indices': cat_indices})\n",
        "\n",
        "# --- Step 1.4: Ordinal Encoding & Vectorization ---\n",
        "print(\"\\n--- Step 1.4: Ordinal Encoding & Vectorization ---\")\n",
        "print(\"  Description: Converts categorical and string columns into numerical representations suitable for the model, including handling missing string values.\")\n",
        "ord_encoder = get_ordinal_encoder()\n",
        "X_fixed_strs = process_text_na_dataframe(X_fixed_dtypes, ord_encoder=ord_encoder, fit_encoder=True)\n",
        "y_fixed_strs = y_fixed_dtypes.copy()\n",
        "display_dataset_state(pd.DataFrame(X_fixed_strs), \"Step 1.4 Output (After Ordinal Encoding)\")\n",
        "print(\"Action: 'Sex' and 'Embarked' were ordinal encoded. String columns ('Ticket', 'Name', 'Cabin') were also vectorized.\")\n",
        "print(\"Action: Column order might have changed due to preprocessing.\")\n",
        "\n",
        "print(\"==================================================\")\n",
        "print(\"--- End Initial Dataset Preprocessing Steps ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZC9oDAic3Sb",
        "outputId": "2473ea51-0798-4f92-dc27-08620cb4790c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Output from _initialize_dataset_preprocessing (for comparison)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "     Dtype  Null Count  Null %\n",
            "0  float64           0    0.00\n",
            "1  float64           0    0.00\n",
            "2  float64           0    0.00\n",
            "3  float64           0    0.00\n",
            "4  float64           0    0.00\n",
            "5  float64           0    0.00\n",
            "6  float64         163   20.35\n",
            "7  float64           0    0.00\n",
            "8  float64           0    0.00\n",
            "9  float64         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     0    1    2      3      4      5     6    7    8        9\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py:566: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
            "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
            "  X_raw: single or list of input dataset features, in case of single it\n"
          ]
        }
      ],
      "source": [
        "# @title Run the `_initialize_dataset_preprocessing`\n",
        "# This is what the original _initialize_dataset_preprocessing returns after these steps\n",
        "# (Note: The original _initialize_dataset_preprocessing might internally handle copying and numpy conversion.)\n",
        "_, X_processed, y_processed = clf._initialize_dataset_preprocessing(X_raw, y_raw, rng=42)\n",
        "display_dataset_state(pd.DataFrame(X_processed), \"Combined Output from _initialize_dataset_preprocessing (for comparison)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f45813c"
      },
      "source": [
        "## Step 2. TabPFN's 'Ensemble Views' & Preprocessing\n",
        "\n",
        "TabPFN enhances model robustness by generating multiple 'ensemble views' of the same dataset. Each view is a unique transformation of the input data, providing diverse perspectives to the neural network, akin to observing an object from different angles. This diversity prevents the model from relying on a single data representation and improves generalization.\n",
        "\n",
        "### Preprocessing Pipeline for Each View:\n",
        "\n",
        "Each view undergoes a specific four-step pipeline before reaching the neural network:\n",
        "\n",
        "1.  **Remove Constant Features:** Eliminates columns with no variance (all identical values) as they offer no predictive power and can disrupt some transformations.\n",
        "\n",
        "2.  **Reshape Distributions:** Applies various scaling (e.g., quantile or power transformations) to numerical features. This crucial step diversifies the data's representation, preparing it for the neural network.\n",
        "\n",
        "3.  **Encode Categorical Features:** Further processes categorical variables, often by shuffling their assigned integer IDs. This randomization prevents the network from inferring meaning from arbitrary numerical order.\n",
        "\n",
        "4.  **Shuffle Features:** Randomizes the column order. This ensures the model learns from feature content rather than their position, enhancing robustness.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcClnXnu7jAU",
        "outputId": "d582ec57-4054-464b-cf17-ad6d4f2fb9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1 Output (Global Preprocessed Data)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "     Dtype  Null Count  Null %\n",
            "0  float64           0    0.00\n",
            "1  float64           0    0.00\n",
            "2  float64           0    0.00\n",
            "3  float64           0    0.00\n",
            "4  float64           0    0.00\n",
            "5  float64           0    0.00\n",
            "6  float64         163   20.35\n",
            "7  float64           0    0.00\n",
            "8  float64           0    0.00\n",
            "9  float64         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     0    1    2      3      4      5     6    7    8        9\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN\n",
            "==================================================\n",
            "\n",
            "\n",
            "Ensemble Configurations:\n",
            "========================================\n",
            "View 1:\n",
            "  - Polynomial Features: no\n",
            "  - Preprocessing: quantile_uni_coarse\n",
            "  - Categorical Encoding: ordinal_very_common_categories_shuffled\n",
            "  - Fingerprint Feature: True\n",
            "  - Feature Shuffle Method: shuffle\n",
            "  - Class Permutation: [0, 1]\n",
            "\n",
            "View 2:\n",
            "  - Polynomial Features: no\n",
            "  - Preprocessing: quantile_uni_coarse\n",
            "  - Categorical Encoding: ordinal_very_common_categories_shuffled\n",
            "  - Fingerprint Feature: True\n",
            "  - Feature Shuffle Method: shuffle\n",
            "  - Class Permutation: [0, 1]\n",
            "\n",
            "View 3:\n",
            "  - Polynomial Features: no\n",
            "  - Preprocessing: none\n",
            "  - Categorical Encoding: numeric\n",
            "  - Fingerprint Feature: True\n",
            "  - Feature Shuffle Method: shuffle\n",
            "  - Class Permutation: [1, 0]\n",
            "\n",
            "View 4:\n",
            "  - Polynomial Features: no\n",
            "  - Preprocessing: none\n",
            "  - Categorical Encoding: numeric\n",
            "  - Fingerprint Feature: True\n",
            "  - Feature Shuffle Method: shuffle\n",
            "  - Class Permutation: [1, 0]\n",
            "\n",
            "Selected View 1 for Detailed Walkthrough\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py:566: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
            "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
            "  X_raw: single or list of input dataset features, in case of single it\n"
          ]
        }
      ],
      "source": [
        "# @title Step 2.0: Show preprocessed dataset, and select configuration\n",
        "\n",
        "from tabpfn.preprocessors import (\n",
        "    RemoveConstantFeaturesStep,\n",
        "    ReshapeFeatureDistributionsStep,\n",
        "    EncodeCategoricalFeaturesStep,\n",
        "    ShuffleFeaturesStep,\n",
        "    AddFingerprintFeaturesStep,\n",
        "    NanHandlingPolynomialFeaturesStep\n",
        ")\n",
        "\n",
        "# --- Step 2.0: Setup & Configuration Selection ---\n",
        "# 1. Get the global preprocessed data and the list of configurations for all views\n",
        "ensemble_configs, X_processed, y_processed = clf._initialize_dataset_preprocessing(X_raw, y_raw, rng=42)\n",
        "display_dataset_state(X_processed, \"Step 1 Output (Global Preprocessed Data)\")\n",
        "\n",
        "# 2. Identify Categorical Indices\n",
        "#    The first transformer [0] is always the 'ordinal encoder'.\n",
        "#    The third element [2] contains the actual list of columns it selected.\n",
        "input_cat_cols = clf.preprocessor_.transformers_[0][2]\n",
        "#    Because Step 1 moves these columns to the front, their indices are 0 to N-1\n",
        "cat_ix = list(range(len(input_cat_cols)))\n",
        "print(\"\\n\\nEnsemble Configurations:\\n\" + \"=\" * 40)\n",
        "\n",
        "for i, config in enumerate(ensemble_configs):\n",
        "    preprocess_name = config.preprocess_config.name if config.preprocess_config else 'N/A'\n",
        "    categorical_name = config.preprocess_config.categorical_name if config.preprocess_config else 'N/A'\n",
        "    feature_shift_decoder = config.feature_shift_decoder\n",
        "    poly_features = config.polynomial_features\n",
        "    fingerprint = config.add_fingerprint_feature\n",
        "    class_perm_display = 'N/A'\n",
        "    if hasattr(config, 'class_permutation') and config.class_permutation is not None:\n",
        "        class_perm_display = config.class_permutation.tolist()\n",
        "\n",
        "    print(f\"View {i+1}:\\n\" \\\n",
        "          f\"  - Polynomial Features: {poly_features}\\n\" \\\n",
        "          f\"  - Preprocessing: {preprocess_name}\\n\" \\\n",
        "          f\"  - Categorical Encoding: {categorical_name}\\n\" \\\n",
        "          f\"  - Fingerprint Feature: {fingerprint}\\n\" \\\n",
        "          f\"  - Feature Shuffle Method: {feature_shift_decoder}\\n\" \\\n",
        "          f\"  - Class Permutation: {class_perm_display}\\n\")\n",
        "\n",
        "# 3. Select one specific view (estimator) to visualize\n",
        "view_num = 0\n",
        "curr_seed = 42\n",
        "curr_config = ensemble_configs[view_num]\n",
        "print(f\"Selected View {view_num+1} for Detailed Walkthrough\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATv0gZim6emn",
        "outputId": "c293c856-6214-4947-f860-efd734ec04a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Start Ensemble View Preprocessing Steps ---\n",
            "==================================================\n",
            "\n",
            "--- Step 2.1: Polynomial Features ---\n",
            "  Description: Generates interaction features (e.g., A*B) if enabled in config.\n",
            "  🔸 Config for NanHandlingPolynomialFeaturesStep:\n",
            "    - Polynomial Features Setting: no\n",
            "Action: Polynomial features disabled (Pass through).\n",
            "\n",
            "--- Step 2.2: Remove Constant Features ---\n",
            "  Description: Features with 0 variance (all same value) provide no info and break some scalers.\n",
            "\n",
            "Step 2.2 Output (After Removing Constant Features)\n",
            "==================================================\n",
            "Shape: (801, 10)\n",
            "\n",
            "Column Summary:\n",
            "     Dtype  Null Count  Null %\n",
            "0  float64           0    0.00\n",
            "1  float64           0    0.00\n",
            "2  float64           0    0.00\n",
            "3  float64           0    0.00\n",
            "4  float64           0    0.00\n",
            "5  float64           0    0.00\n",
            "6  float64         163   20.35\n",
            "7  float64           0    0.00\n",
            "8  float64           0    0.00\n",
            "9  float64         620   77.40\n",
            "\n",
            "Head of DataFrame:\n",
            "     0    1    2      3      4      5     6    7    8        9\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN\n",
            "==================================================\n",
            "Action: No constant columns found (Pass through).\n",
            "\n",
            "--- Step 2.3: Reshape Distributions (The 'View' Creator) ---\n",
            "  Description: This step applies various scaling (Quantile, Power, or None) to numerical features.\n",
            "  🔸 Config for ReshapeFeatureDistributionsStep:\n",
            "    - Transformation Type: quantile_uni_coarse\n",
            "    - Append Original Features: auto\n",
            "    - Max Features per Estimator: 1000000\n",
            "\n",
            "Step 2.3 Output (After Scaling)\n",
            "==================================================\n",
            "Shape: (801, 19)\n",
            "\n",
            "Column Summary:\n",
            "      Dtype  Null Count  Null %\n",
            "0   float64           0    0.00\n",
            "1   float64           0    0.00\n",
            "2   float64           0    0.00\n",
            "3   float64           0    0.00\n",
            "4   float64           0    0.00\n",
            "5   float64           0    0.00\n",
            "6   float64         163   20.35\n",
            "7   float64           0    0.00\n",
            "8   float64           0    0.00\n",
            "9   float64         620   77.40\n",
            "10  float64         163   20.35\n",
            "11  float64           0    0.00\n",
            "12  float64           0    0.00\n",
            "13  float64         620   77.40\n",
            "14  float64           0    0.00\n",
            "15  float64           0    0.00\n",
            "16  float64           0    0.00\n",
            "17  float64           0    0.00\n",
            "18  float64           0    0.00\n",
            "\n",
            "Head of DataFrame:\n",
            "    0    1    2      3      4      5     6    7    8        9         10        11        12        13        14        15        16        17        18\n",
            "0  2.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN  0.132911  0.803797  0.987342       NaN  8.204553  3.760629  1.101507 -0.757295 -0.217848\n",
            "1  0.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792  0.132911  0.000000  0.822785  0.532749  3.732376  1.464718 -2.515867  0.916025  0.931499\n",
            "2  2.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN       NaN  0.000000  0.000000       NaN  8.069995 -1.022730  0.966393  0.754798  1.024711\n",
            "3  2.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN  0.151899  0.000000  0.000000       NaN  7.044104 -0.092992  1.683987  1.267281 -1.313677\n",
            "4  2.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN  0.272152  0.000000  0.000000       NaN  7.157699 -0.341742  1.417963  0.993075 -1.573132\n",
            "==================================================\n",
            "\n",
            "--- Step 2.4: Shuffle Categorical Encoding ---\n",
            "  Description: Handles model-specific categorical encoding (often permuting integer IDs).\n",
            "  🔸 Config for EncodeCategoricalFeaturesStep:\n",
            "    - Categorical Transform Name: ordinal_very_common_categories_shuffled\n",
            "\n",
            "Step 2.4 Output (After Categorical Encoding)\n",
            "==================================================\n",
            "Shape: (801, 19)\n",
            "\n",
            "Column Summary:\n",
            "      Dtype  Null Count  Null %\n",
            "0   float64           0    0.00\n",
            "1   float64           0    0.00\n",
            "2   float64           0    0.00\n",
            "3   float64           0    0.00\n",
            "4   float64           0    0.00\n",
            "5   float64           0    0.00\n",
            "6   float64         163   20.35\n",
            "7   float64           0    0.00\n",
            "8   float64           0    0.00\n",
            "9   float64         620   77.40\n",
            "10  float64         163   20.35\n",
            "11  float64           0    0.00\n",
            "12  float64           0    0.00\n",
            "13  float64         620   77.40\n",
            "14  float64           0    0.00\n",
            "15  float64           0    0.00\n",
            "16  float64           0    0.00\n",
            "17  float64           0    0.00\n",
            "18  float64           0    0.00\n",
            "\n",
            "Head of DataFrame:\n",
            "    0    1    2      3      4      5     6    7    8        9         10        11        12        13        14        15        16        17        18\n",
            "0  0.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN  0.132911  0.803797  0.987342       NaN  8.204553  3.760629  1.101507 -0.757295 -0.217848\n",
            "1  2.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792  0.132911  0.000000  0.822785  0.532749  3.732376  1.464718 -2.515867  0.916025  0.931499\n",
            "2  0.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN       NaN  0.000000  0.000000       NaN  8.069995 -1.022730  0.966393  0.754798  1.024711\n",
            "3  0.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN  0.151899  0.000000  0.000000       NaN  7.044104 -0.092992  1.683987  1.267281 -1.313677\n",
            "4  0.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN  0.272152  0.000000  0.000000       NaN  7.157699 -0.341742  1.417963  0.993075 -1.573132\n",
            "==================================================\n",
            "\n",
            "--- Step 2.5: Add Fingerprint Feature ---\n",
            "  Description: Adds a hashed 'ID' feature to help the Transformer track rows across shuffling.\n",
            "  🔸 Config for AddFingerprintFeaturesStep:\n",
            "    - Fingerprint Enabled: True\n",
            "\n",
            "Step 2.5 Output (After Fingerprinting)\n",
            "==================================================\n",
            "Shape: (801, 20)\n",
            "\n",
            "Column Summary:\n",
            "      Dtype  Null Count  Null %\n",
            "0   float64           0    0.00\n",
            "1   float64           0    0.00\n",
            "2   float64           0    0.00\n",
            "3   float64           0    0.00\n",
            "4   float64           0    0.00\n",
            "5   float64           0    0.00\n",
            "6   float64         163   20.35\n",
            "7   float64           0    0.00\n",
            "8   float64           0    0.00\n",
            "9   float64         620   77.40\n",
            "10  float64         163   20.35\n",
            "11  float64           0    0.00\n",
            "12  float64           0    0.00\n",
            "13  float64         620   77.40\n",
            "14  float64           0    0.00\n",
            "15  float64           0    0.00\n",
            "16  float64           0    0.00\n",
            "17  float64           0    0.00\n",
            "18  float64           0    0.00\n",
            "19  float64           0    0.00\n",
            "\n",
            "Head of DataFrame:\n",
            "    0    1    2      3      4      5     6    7    8        9         10        11        12        13        14        15        16        17        18        19\n",
            "0  0.0  1.0  2.0  620.0  227.0  136.0  16.0  1.0  3.0      NaN  0.132911  0.803797  0.987342       NaN  8.204553  3.760629  1.101507 -0.757295 -0.217848  0.557488\n",
            "1  2.0  0.0  0.0    7.0  325.0   16.0  16.0  0.0  1.0  57.9792  0.132911  0.000000  0.822785  0.532749  3.732376  1.464718 -2.515867  0.916025  0.931499  0.869508\n",
            "2  0.0  1.0  1.0  433.0  642.0  136.0   NaN  0.0  0.0      NaN       NaN  0.000000  0.000000       NaN  8.069995 -1.022730  0.966393  0.754798  1.024711  0.810000\n",
            "3  0.0  1.0  2.0  248.0  164.0  136.0  17.0  0.0  0.0      NaN  0.151899  0.000000  0.000000       NaN  7.044104 -0.092992  1.683987  1.267281 -1.313677  0.789209\n",
            "4  0.0  1.0  2.0  239.0   75.0  136.0  21.0  0.0  0.0      NaN  0.272152  0.000000  0.000000       NaN  7.157699 -0.341742  1.417963  0.993075 -1.573132  0.673708\n",
            "==================================================\n",
            "Action: Added a high-cardinality float column (hash of the row).\n",
            "\n",
            "--- Step 2.6: Shuffle Column Order ---\n",
            "  Description: Randomizes column order so the model isn't dependent on feature position.\n",
            "  🔸 Config for ShuffleFeaturesStep:\n",
            "    - Shuffle Method: shuffle\n",
            "    - Shuffle Index: 92\n",
            "\n",
            "Step 2.6 Output (After Column Shuffling)\n",
            "==================================================\n",
            "Shape: (801, 20)\n",
            "\n",
            "Column Summary:\n",
            "      Dtype  Null Count  Null %\n",
            "0   float64           0    0.00\n",
            "1   float64         620   77.40\n",
            "2   float64           0    0.00\n",
            "3   float64           0    0.00\n",
            "4   float64           0    0.00\n",
            "5   float64         163   20.35\n",
            "6   float64         163   20.35\n",
            "7   float64           0    0.00\n",
            "8   float64           0    0.00\n",
            "9   float64           0    0.00\n",
            "10  float64           0    0.00\n",
            "11  float64           0    0.00\n",
            "12  float64           0    0.00\n",
            "13  float64           0    0.00\n",
            "14  float64           0    0.00\n",
            "15  float64           0    0.00\n",
            "16  float64           0    0.00\n",
            "17  float64           0    0.00\n",
            "18  float64         620   77.40\n",
            "19  float64           0    0.00\n",
            "\n",
            "Head of DataFrame:\n",
            "         0        1         2    3         4         5     6         7      8    9         10     11        12        13   14     15        16   17        18   19\n",
            "0  3.760629      NaN  8.204553  1.0  0.987342  0.132911  16.0  0.557488  620.0  0.0  1.101507  136.0  0.803797 -0.217848  2.0  227.0 -0.757295  1.0       NaN  3.0\n",
            "1  1.464718  57.9792  3.732376  0.0  0.822785  0.132911  16.0  0.869508    7.0  2.0 -2.515867   16.0  0.000000  0.931499  0.0  325.0  0.916025  0.0  0.532749  1.0\n",
            "2 -1.022730      NaN  8.069995  0.0  0.000000       NaN   NaN  0.810000  433.0  0.0  0.966393  136.0  0.000000  1.024711  1.0  642.0  0.754798  1.0       NaN  0.0\n",
            "3 -0.092992      NaN  7.044104  0.0  0.000000  0.151899  17.0  0.789209  248.0  0.0  1.683987  136.0  0.000000 -1.313677  2.0  164.0  1.267281  1.0       NaN  0.0\n",
            "4 -0.341742      NaN  7.157699  0.0  0.000000  0.272152  21.0  0.673708  239.0  0.0  1.417963  136.0  0.000000 -1.573132  2.0   75.0  0.993075  1.0       NaN  0.0\n",
            "==================================================\n",
            "Shuffle Map: [15, 9, 14, 7, 12, 10, 6, 19, 3, 0, 16, 5, 11, 18, 2, 4, 17, 1, 13, 8]\n",
            "Action: The columns (including the fingerprint!) are now scrambled.\n",
            "\n",
            "==================================================\n",
            "--- End Ensemble View Preprocessing Steps ---\n"
          ]
        }
      ],
      "source": [
        "# @title Step 2.1-2.6: Full Ensemble View Preprocessing Pipeline\n",
        "\n",
        "print(\"--- Start Ensemble View Preprocessing Steps ---\")\n",
        "print(\"==================================================\")\n",
        "\n",
        "# --- Step 2.1: Polynomial Features ---\n",
        "print(\"\\n--- Step 2.1: Polynomial Features ---\")\n",
        "print(\"  Description: Generates interaction features (e.g., A*B) if enabled in config.\")\n",
        "poly_feats = curr_config.polynomial_features\n",
        "print(f\"  🔸 Config for NanHandlingPolynomialFeaturesStep:\")\n",
        "print(f\"    - Polynomial Features Setting: {poly_feats}\")\n",
        "\n",
        "# Determine if we run it (logic from src/tabpfn/preprocessing.py)\n",
        "use_poly = poly_feats != \"no\"\n",
        "max_poly = None if poly_feats == \"all\" else (poly_feats if isinstance(poly_feats, int) else None)\n",
        "\n",
        "if use_poly:\n",
        "    step_2_1 = NanHandlingPolynomialFeaturesStep(\n",
        "        max_features=max_poly,\n",
        "        random_state=curr_seed\n",
        "    )\n",
        "    # Input is X_processed from Step 1\n",
        "    res_2_1 = step_2_1.fit_transform(X_processed, cat_ix)\n",
        "    X_2_1 = res_2_1.X\n",
        "    cats_ix_2_1 = res_2_1.categorical_features\n",
        "    display_dataset_state(X_2_1, \"Step 2.1 Output (After Polynomial Features)\")\n",
        "else:\n",
        "    print(\"Action: Polynomial features disabled (Pass through).\")\n",
        "    X_2_1 = X_processed\n",
        "    cats_ix_2_1 = cat_ix\n",
        "\n",
        "\n",
        "# --- Step 2.2: Remove Constant Features ---\n",
        "print(\"\\n--- Step 2.2: Remove Constant Features ---\")\n",
        "print(\"  Description: Features with 0 variance (all same value) provide no info and break some scalers.\")\n",
        "step_2_2 = RemoveConstantFeaturesStep()\n",
        "# Input is X_2_1\n",
        "res_2_2 = step_2_2.fit_transform(X_2_1, cats_ix_2_1)\n",
        "X_2_2 = res_2_2.X\n",
        "cats_ix_2_2 = res_2_2.categorical_features\n",
        "display_dataset_state(X_2_2, \"Step 2.2 Output (After Removing Constant Features)\")\n",
        "\n",
        "if X_2_2.shape[1] < X_2_1.shape[1]:\n",
        "    print(\"Action: Removed constant columns!\")\n",
        "else:\n",
        "    print(\"Action: No constant columns found (Pass through).\")\n",
        "\n",
        "\n",
        "# --- Step 2.3: Reshape Distributions (The \"View\" Creator) ---\n",
        "print(\"\\n--- Step 2.3: Reshape Distributions (The 'View' Creator) ---\")\n",
        "print(\"  Description: This step applies various scaling (Quantile, Power, or None) to numerical features.\")\n",
        "transform_name = curr_config.preprocess_config.name\n",
        "append_to_original = curr_config.preprocess_config.append_original\n",
        "max_features_per_estimator = curr_config.preprocess_config.max_features_per_estimator\n",
        "global_transformer_name = curr_config.preprocess_config.global_transformer_name\n",
        "apply_to_categorical = (curr_config.preprocess_config.categorical_name == \"numeric\")\n",
        "\n",
        "print(f\"  🔸 Config for ReshapeFeatureDistributionsStep:\")\n",
        "print(f\"    - Transformation Type: {transform_name}\")\n",
        "print(f\"    - Append Original Features: {append_to_original}\")\n",
        "print(f\"    - Max Features per Estimator: {max_features_per_estimator}\")\n",
        "\n",
        "step_2_3 = ReshapeFeatureDistributionsStep(\n",
        "    transform_name=transform_name,\n",
        "    append_to_original=append_to_original,\n",
        "    max_features_per_estimator=max_features_per_estimator,\n",
        "    global_transformer_name=global_transformer_name,\n",
        "    apply_to_categorical=apply_to_categorical,\n",
        "    random_state=curr_seed\n",
        ")\n",
        "# Input is X_2_2\n",
        "res_2_3 = step_2_3.fit_transform(X_2_2, cats_ix_2_2)\n",
        "X_2_3 = res_2_3.X\n",
        "cats_ix_2_3 = res_2_3.categorical_features\n",
        "display_dataset_state(X_2_3, \"Step 2.3 Output (After Scaling)\")\n",
        "\n",
        "\n",
        "# --- Step 2.4: Shuffle Categorical Encoding ---\n",
        "print(\"\\n--- Step 2.4: Shuffle Categorical Encoding ---\")\n",
        "print(\"  Description: Handles model-specific categorical encoding (often permuting integer IDs).\")\n",
        "cat_method = curr_config.preprocess_config.categorical_name\n",
        "print(f\"  🔸 Config for EncodeCategoricalFeaturesStep:\")\n",
        "print(f\"    - Categorical Transform Name: {cat_method}\")\n",
        "\n",
        "step_2_4 = EncodeCategoricalFeaturesStep(\n",
        "    categorical_transform_name=cat_method,\n",
        "    random_state=curr_seed\n",
        ")\n",
        "# Input is X_2_3\n",
        "res_2_4 = step_2_4.fit_transform(X_2_3, cats_ix_2_3)\n",
        "X_2_4 = res_2_4.X\n",
        "cats_ix_2_4 = res_2_4.categorical_features\n",
        "display_dataset_state(X_2_4, \"Step 2.4 Output (After Categorical Encoding)\")\n",
        "\n",
        "\n",
        "# --- Step 2.5: Add Fingerprint Feature ---\n",
        "print(\"\\n--- Step 2.5: Add Fingerprint Feature ---\")\n",
        "print(\"  Description: Adds a hashed 'ID' feature to help the Transformer track rows across shuffling.\")\n",
        "add_fp = curr_config.add_fingerprint_feature\n",
        "print(f\"  🔸 Config for AddFingerprintFeaturesStep:\")\n",
        "print(f\"    - Fingerprint Enabled: {add_fp}\")\n",
        "\n",
        "if add_fp:\n",
        "    step_2_5 = AddFingerprintFeaturesStep(random_state=curr_seed)\n",
        "    # Input is X_2_4\n",
        "    res_2_5 = step_2_5.fit_transform(X_2_4, cats_ix_2_4)\n",
        "    X_2_5 = res_2_5.X\n",
        "    cats_ix_2_5 = res_2_5.categorical_features\n",
        "    display_dataset_state(X_2_5, \"Step 2.5 Output (After Fingerprinting)\")\n",
        "    print(\"Action: Added a high-cardinality float column (hash of the row).\")\n",
        "else:\n",
        "    print(\"Action: Fingerprinting disabled.\")\n",
        "    X_2_5 = X_2_4\n",
        "    cats_ix_2_5 = cats_ix_2_4\n",
        "\n",
        "\n",
        "# --- Step 2.6: Shuffle Column Order ---\n",
        "print(\"\\n--- Step 2.6: Shuffle Column Order ---\")\n",
        "print(\"  Description: Randomizes column order so the model isn't dependent on feature position.\")\n",
        "print(f\"  🔸 Config for ShuffleFeaturesStep:\")\n",
        "print(f\"    - Shuffle Method: {curr_config.feature_shift_decoder}\")\n",
        "print(f\"    - Shuffle Index: {curr_config.feature_shift_count}\")\n",
        "\n",
        "step_2_6 = ShuffleFeaturesStep(\n",
        "    shuffle_method=curr_config.feature_shift_decoder,\n",
        "    shuffle_index=curr_config.feature_shift_count,\n",
        "    random_state=curr_seed\n",
        ")\n",
        "# Input is X_2_5\n",
        "res_2_6 = step_2_6.fit_transform(X_2_5, cats_ix_2_5)\n",
        "X_2_6 = res_2_6.X\n",
        "cats_ix_2_6 = res_2_6.categorical_features\n",
        "display_dataset_state(X_2_6, \"Step 2.6 Output (After Column Shuffling)\")\n",
        "\n",
        "print(f\"Shuffle Map: {step_2_6.index_permutation_}\")\n",
        "print(\"Action: The columns (including the fingerprint!) are now scrambled.\")\n",
        "\n",
        "\n",
        "print(\"\\n==================================================\")\n",
        "print(\"--- End Ensemble View Preprocessing Steps ---\")\n",
        "\n",
        "# Final assignment\n",
        "X_view = X_2_6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-ZrcjHidlIP",
        "outputId": "ca303010-1d42-499d-db6f-6d848eb7f0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2 Output - View 1\n",
            "==================================================\n",
            "Shape: (801, 20)\n",
            "\n",
            "Column Summary:\n",
            "      Dtype  Null Count  Null %\n",
            "0   float64           0    0.00\n",
            "1   float64         620   77.40\n",
            "2   float64           0    0.00\n",
            "3   float64           0    0.00\n",
            "4   float64           0    0.00\n",
            "5   float64         163   20.35\n",
            "6   float64         163   20.35\n",
            "7   float64           0    0.00\n",
            "8   float64           0    0.00\n",
            "9   float64           0    0.00\n",
            "10  float64           0    0.00\n",
            "11  float64           0    0.00\n",
            "12  float64           0    0.00\n",
            "13  float64           0    0.00\n",
            "14  float64           0    0.00\n",
            "15  float64           0    0.00\n",
            "16  float64           0    0.00\n",
            "17  float64           0    0.00\n",
            "18  float64         620   77.40\n",
            "19  float64           0    0.00\n",
            "\n",
            "Head of DataFrame:\n",
            "         0        1         2    3         4         5     6         7      8    9         10     11        12        13   14     15        16   17        18   19\n",
            "0  3.760629      NaN  8.204553  1.0  0.987342  0.132911  16.0  0.557488  620.0  0.0  1.101507  136.0  0.803797 -0.217848  2.0  227.0 -0.757295  1.0       NaN  3.0\n",
            "1  1.464718  57.9792  3.732376  0.0  0.822785  0.132911  16.0  0.869508    7.0  2.0 -2.515867   16.0  0.000000  0.931499  0.0  325.0  0.916025  0.0  0.532749  1.0\n",
            "2 -1.022730      NaN  8.069995  0.0  0.000000       NaN   NaN  0.810000  433.0  0.0  0.966393  136.0  0.000000  1.024711  1.0  642.0  0.754798  1.0       NaN  0.0\n",
            "3 -0.092992      NaN  7.044104  0.0  0.000000  0.151899  17.0  0.789209  248.0  0.0  1.683987  136.0  0.000000 -1.313677  2.0  164.0  1.267281  1.0       NaN  0.0\n",
            "4 -0.341742      NaN  7.157699  0.0  0.000000  0.272152  21.0  0.673708  239.0  0.0  1.417963  136.0  0.000000 -1.573132  2.0   75.0  0.993075  1.0       NaN  0.0\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# @title Run the step with view's pipeline\n",
        "# We use the internal method to reproduce the preprocessing exactly\n",
        "# This returns the numpy array that TabPFN actually uses\n",
        "\n",
        "curr_pipeline = curr_config.to_pipeline(random_state=42)\n",
        "\n",
        "res = curr_pipeline.fit_transform(X_processed, cat_ix)\n",
        "\n",
        "X_view = res.X\n",
        "\n",
        "display_dataset_state(X_view, \"Step 2 Output - View 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8OJAcqW1kHU"
      },
      "source": [
        "## Step 3. Transform Dataset View to Embedding Tensor\n",
        "\n",
        "Each ensemble view undergoes a sequence of transformations to convert the table data into high-dimensional embeddings for the neural network.\n",
        "\n",
        "### 1. Input Reshaping & Flattening\n",
        "The raw features are restructured into the format expected by the Transformer backbone.\n",
        "* **Initial Reshaping:** Convert to `(Sequence, Batch, Features)`. Example: `(801, 1, 20)`.\n",
        "* **Padding:** If features aren't divisible by the group size (2), zero-padding columns are added.\n",
        "* **Grouping & Flattening:** Features are grouped, and the Batch dimension is merged with Groups to form an \"Effective Batch.\"\n",
        "    * *Transformation:* `(Seq, Batch, Feat) -> (Seq, Batch, Groups, GrpSize) -> (Seq, FlatBatch, GrpSize)`\n",
        "    * *Example:* `(801, 1, 20) -> (801, 1, 10, 2) -> (801, 10, 2)`.\n",
        "\n",
        "### 2. Encoder Pipeline (Steps 3.1 - 3.6)\n",
        "The encoder processes these feature groups through a sequence of steps:\n",
        "\n",
        "* **Step 3.1: Remove Constant Features** (`RemoveEmptyFeaturesEncoderStep`)\n",
        "    Drops features with zero variance across the sequence.\n",
        "* **Step 3.2: NaN Handling** (`NanHandlingEncoderStep`)\n",
        "    Imputes missing values with the mean and adds binary **NaN indicator columns**.\n",
        "    * *Dimension Change:* Group size doubles from **2** to **4** (2 values + 2 indicators).\n",
        "* **Step 3.3: Variable Feature Adjustment** (`VariableNumFeaturesEncoderStep`)\n",
        "    Aligns data structure with model expectations for variable feature counts.\n",
        "* **Step 3.4: Normalization** (`InputNormalizationEncoderStep`)\n",
        "    Standardizes features (mean 0, variance 1) and clips extreme outliers.\n",
        "* **Step 3.5: Secondary Adjustment** (`VariableNumFeaturesEncoderStep`)\n",
        "    Ensures consistency after normalization.\n",
        "* **Step 3.6: Linear Embedding** (`LinearInputEncoderStep`)\n",
        "    Projects the processed groups into the model's hidden dimension.\n",
        "    * *Transformation:* Linear layer maps size **4** to **192**.\n",
        "    * *Final Shape:* `(801, 10, 192)`.\n",
        "\n",
        "The result is a `(801, 10, 192)` tensor ready for the Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfI51ukxUb1x",
        "outputId": "39165c29-c5e0-4905-d49a-3a9c8d44b960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model requirement: Groups of 2 features\n",
            "\n",
            "Initial X_view shape: (801, 20) (Seq, Feat)\n",
            "X_tensor shape after unsqueeze(0): torch.Size([1, 801, 20]) (Batch, Seq, Feat)\n",
            "\n",
            "--- Padding Step ---\n",
            "No Padding Needed, features already divisible by 2\n",
            "X_padded shape: torch.Size([1, 801, 20]) (Batch, Seq, PaddedFeat)\n",
            "\n",
            "--- Flattening Step ---\n",
            "X_grouped shape (Batch, Seq, NumGroups, GroupSize): torch.Size([1, 801, 10, 2])\n",
            "X_flat shape (Sequence, FlatBatch (Batch*NumGroups), GroupSize): torch.Size([801, 10, 2])\n",
            "   (Sequence=801, FlatBatch (1*10)=10, GroupSize=2)\n"
          ]
        }
      ],
      "source": [
        "# @title Step 3.0: Convert dataset to flat tensor\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import einops\n",
        "\n",
        "# Helper function to reconstruct the 2D view (Batch x Features)\n",
        "def view_tensor(tensor, name):\n",
        "    reconstructed = einops.rearrange(tensor, \"s f n -> s (f n)\")\n",
        "\n",
        "    # Extract first 5 rows (Passengers) directly from the Sequence dim\n",
        "    # Shape is (891, 18) -> slice -> (5, 18)\n",
        "    df_data = reconstructed[:5, :].detach().numpy()\n",
        "\n",
        "    df = pd.DataFrame(df_data)\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"   Shape: {tensor.shape}\")\n",
        "    print(f\"   View:  (Showing 5 rows x {df.shape[1]} cols)\")\n",
        "    print(df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "def view_embedding(tensor, name):\n",
        "    # Shape: (Seq=891, Groups=9, Dim=192)\n",
        "\n",
        "    # We flatten Groups and Dims to see the full \"Row Vector\"\n",
        "    # s f d -> s (f d)\n",
        "    # 891 x 9 x 192 -> 891 x 1728\n",
        "    flattened = einops.rearrange(tensor, \"s f d -> s (f d)\")\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"   Shape: {tensor.shape} (Seq, Groups, Dim)\")\n",
        "    print(f\"   Flattened View: {flattened.shape} (Seq, Total_Embedding_Size)\")\n",
        "\n",
        "    # Show first 5 passengers, first 8 dimensions\n",
        "    df = pd.DataFrame(flattened[:5, :].detach().numpy())\n",
        "    df.columns = [f\"Dim_{i}\" for i in range(df.shape[1])]\n",
        "\n",
        "    print(\"   Preview (First 8 dims of Group 0):\")\n",
        "    print(df.iloc[:, :8].to_string(index=False, float_format=\"%.4f\"))\n",
        "    print(f\"   ... (+ {df.shape[1]-8} more columns) ...\")\n",
        "\n",
        "\n",
        "X_tensor = torch.as_tensor(X_view, dtype=torch.float32).unsqueeze(0)\n",
        "model = clf.models_[0]\n",
        "encoder_steps = model.encoder\n",
        "n_features_per_group = model.features_per_group\n",
        "\n",
        "print(f\"Model requirement: Groups of {n_features_per_group} features\")\n",
        "print(f\"\\nInitial X_view shape: {X_view.shape} (Seq, Feat)\")\n",
        "print(f\"X_tensor shape after unsqueeze(0): {X_tensor.shape} (Batch, Seq, Feat)\")\n",
        "\n",
        "# 1. PAD (Must be divisible by Group Size)\n",
        "print(\"\\n--- Padding Step ---\")\n",
        "remainder = X_tensor.shape[-1] % n_features_per_group\n",
        "if remainder > 0:\n",
        "  padding = n_features_per_group - remainder\n",
        "  print(f\"⚠️ Padding with {padding} zero-column(s) to make features divisible by {n_features_per_group}...\")\n",
        "  X_padded = F.pad(X_tensor, (0, padding))\n",
        "else:\n",
        "  print(f\"No Padding Needed, features already divisible by {n_features_per_group}\")\n",
        "  X_padded = X_tensor\n",
        "print(f\"X_padded shape: {X_padded.shape} (Batch, Seq, PaddedFeat)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. FLATTEN\n",
        "# ==========================================\n",
        "print(\"\\n--- Flattening Step ---\")\n",
        "# Current Shape: (Batch, Sequence, PaddedFeatures) -> (1, 801, 20)\n",
        "\n",
        "# A. Group features: Rearrange into (Batch, Sequence, NumGroups, GroupSize)\n",
        "# Example: (1, 801, 20) -> (1, 801, 10, 2)\n",
        "X_grouped = einops.rearrange(\n",
        "    X_padded,\n",
        "    \"b s (f n) -> b s f n\",\n",
        "    n=n_features_per_group\n",
        ")\n",
        "print(f\"X_grouped shape (Batch, Seq, NumGroups, GroupSize): {X_grouped.shape}\")\n",
        "\n",
        "# B. Flatten Batch and Groups: Rearrange into (Sequence, FlatBatch, GroupSize)\n",
        "# Here, 'FlatBatch' = Batch * NumGroups\n",
        "# Example: (1, 801, 10, 2) -> (801, 1 * 10, 2) = (801, 10, 2)\n",
        "X_flat = einops.rearrange(X_grouped, \"b s f n -> s (b f) n\")\n",
        "\n",
        "current_inputs = {\"main\": X_flat}\n",
        "single_eval_pos = 0 # Predict using the whole sequence statistics\n",
        "original_batch = 1  # We now effectively have 1 batch\n",
        "\n",
        "print(f\"X_flat shape (Sequence, FlatBatch (Batch*NumGroups), GroupSize): {X_flat.shape}\")\n",
        "print(f\"   (Sequence={X_flat.shape[0]}, FlatBatch (1*{X_grouped.shape[2]})={X_flat.shape[1]}, GroupSize={X_flat.shape[2]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kWxCb2GmHCL",
        "outputId": "f7a05f26-6539-48e9-96f7-1e032db3bb8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RAW INPUT: X_flat\n",
            "   Shape: torch.Size([801, 10, 2])\n",
            "   View:  (Showing 5 rows x 20 cols)\n",
            "     0       1      2      3      4      5       6      7        8      9       10       11     12      13     14       15      16     17     18     19\n",
            " 3.7606     NaN 8.2046 1.0000 0.9873 0.1329 16.0000 0.5575 620.0000 0.0000  1.1015 136.0000 0.8038 -0.2178 2.0000 227.0000 -0.7573 1.0000    NaN 3.0000\n",
            " 1.4647 57.9792 3.7324 0.0000 0.8228 0.1329 16.0000 0.8695   7.0000 2.0000 -2.5159  16.0000 0.0000  0.9315 0.0000 325.0000  0.9160 0.0000 0.5327 1.0000\n",
            "-1.0227     NaN 8.0700 0.0000 0.0000    NaN     NaN 0.8100 433.0000 0.0000  0.9664 136.0000 0.0000  1.0247 1.0000 642.0000  0.7548 1.0000    NaN 0.0000\n",
            "-0.0930     NaN 7.0441 0.0000 0.0000 0.1519 17.0000 0.7892 248.0000 0.0000  1.6840 136.0000 0.0000 -1.3137 2.0000 164.0000  1.2673 1.0000    NaN 0.0000\n",
            "-0.3417     NaN 7.1577 0.0000 0.0000 0.2722 21.0000 0.6737 239.0000 0.0000  1.4180 136.0000 0.0000 -1.5731 2.0000  75.0000  0.9931 1.0000    NaN 0.0000\n",
            "\n",
            "--- Step 3.1: RemoveEmptyFeaturesEncoderStep ---\n",
            "  Description: Encoder step to remove empty (constant) features\n",
            "\n",
            "STEP 3.1 Output (Remove Empty Features)\n",
            "   Shape: torch.Size([801, 10, 2])\n",
            "   View:  (Showing 5 rows x 20 cols)\n",
            "     0       1      2      3      4      5       6      7        8      9       10       11     12      13     14       15      16     17     18     19\n",
            " 3.7606     NaN 8.2046 1.0000 0.9873 0.1329 16.0000 0.5575 620.0000 0.0000  1.1015 136.0000 0.8038 -0.2178 2.0000 227.0000 -0.7573 1.0000    NaN 3.0000\n",
            " 1.4647 57.9792 3.7324 0.0000 0.8228 0.1329 16.0000 0.8695   7.0000 2.0000 -2.5159  16.0000 0.0000  0.9315 0.0000 325.0000  0.9160 0.0000 0.5327 1.0000\n",
            "-1.0227     NaN 8.0700 0.0000 0.0000    NaN     NaN 0.8100 433.0000 0.0000  0.9664 136.0000 0.0000  1.0247 1.0000 642.0000  0.7548 1.0000    NaN 0.0000\n",
            "-0.0930     NaN 7.0441 0.0000 0.0000 0.1519 17.0000 0.7892 248.0000 0.0000  1.6840 136.0000 0.0000 -1.3137 2.0000 164.0000  1.2673 1.0000    NaN 0.0000\n",
            "-0.3417     NaN 7.1577 0.0000 0.0000 0.2722 21.0000 0.6737 239.0000 0.0000  1.4180 136.0000 0.0000 -1.5731 2.0000  75.0000  0.9931 1.0000    NaN 0.0000\n",
            "\n",
            "--- Step 3.2: NanHandlingEncoderStep ---\n",
            "  Description: Encoder step to handle NaN and infinite values in the input\n",
            "  - `keep_nans`: True (If True, adds separate indicator columns for NaNs/Infs)\n",
            "\n",
            "STEP 3.2 Output (NaN Handling)\n",
            "   Shape: torch.Size([801, 10, 2])\n",
            "   View:  (Showing 5 rows x 20 cols)\n",
            "     0       1      2      3      4      5       6      7        8      9       10       11     12      13     14       15      16     17     18     19\n",
            " 3.7606  0.0000 8.2046 1.0000 0.9873 0.1329 16.0000 0.5575 620.0000 0.0000  1.1015 136.0000 0.8038 -0.2178 2.0000 227.0000 -0.7573 1.0000 0.0000 3.0000\n",
            " 1.4647 57.9792 3.7324 0.0000 0.8228 0.1329 16.0000 0.8695   7.0000 2.0000 -2.5159  16.0000 0.0000  0.9315 0.0000 325.0000  0.9160 0.0000 0.5327 1.0000\n",
            "-1.0227  0.0000 8.0700 0.0000 0.0000 0.0000  0.0000 0.8100 433.0000 0.0000  0.9664 136.0000 0.0000  1.0247 1.0000 642.0000  0.7548 1.0000 0.0000 0.0000\n",
            "-0.0930  0.0000 7.0441 0.0000 0.0000 0.1519 17.0000 0.7892 248.0000 0.0000  1.6840 136.0000 0.0000 -1.3137 2.0000 164.0000  1.2673 1.0000 0.0000 0.0000\n",
            "-0.3417  0.0000 7.1577 0.0000 0.0000 0.2722 21.0000 0.6737 239.0000 0.0000  1.4180 136.0000 0.0000 -1.5731 2.0000  75.0000  0.9931 1.0000 0.0000 0.0000\n",
            "\n",
            "--- Step 3.3: VariableNumFeaturesEncoderStep ---\n",
            "  Description: Encoder step to handle variable number of features\n",
            "  - This step typically adds meta-features, such as indicators for original NaN positions, to provide more context to the model.\n",
            "\n",
            "--- Step 3.4: InputNormalizationEncoderStep ---\n",
            "  Description: Encoder step to normalize the input in different ways\n",
            "  - This step normalizes features to a standard scale (e.g., mean 0, variance 1).\n",
            "  - `normalize_x`: True (If True, performs standard mean/std normalization.)\n",
            "  - `remove_outliers`: True (If True, outliers are clipped based on sigma.)\n",
            "  - `remove_outliers_sigma`: 12.0\n",
            "  - `mean` (first 5 values): [-0.1089  0.8877  2.1287  0.2795  0.1534] (Learned means.)\n",
            "  - `std` (first 5 values): [0.8761 1.7097 0.1493 0.4623 0.2711] (Learned standard deviations.)\n",
            "\n",
            "STEP 3.4 Output (Normalization)\n",
            "   Shape: torch.Size([801, 10, 2])\n",
            "   View:  (Showing 5 rows x 20 cols)\n",
            "     0       1       2       3       4       5       6      7       8       9       10      11      12      13      14      15      16      17      18      19\n",
            " 1.9054 -0.5192  0.6099  0.8947  1.9672 -0.7770  0.1687 0.3205  0.9719 -0.8608  0.8197  0.3604  1.3955 -0.3014  0.5628 -0.2664 -0.8242  0.7346 -0.4659  2.7793\n",
            " 1.1540  1.8655 -3.8472 -0.6047  1.6485 -0.7770  0.1687 1.2135 -3.2240  1.4629 -1.6919 -3.3850 -0.6753  1.0370 -1.9866  0.0974  0.9015 -1.3595  1.8154  1.1225\n",
            "-0.6798 -0.5192  0.5113 -0.6047 -0.5659 -1.3066 -1.7860 1.0553  0.6264 -0.8608  0.7362  0.3604 -0.6753  1.1107 -0.3781  0.7885  0.7765  0.7346 -0.4659 -0.5343\n",
            " 0.0228 -0.5192 -0.2929 -0.6047 -0.5659 -0.7065  0.2082 0.9988  0.0908 -0.8608  1.1269  0.3604 -0.6753 -1.3055  0.5628 -0.5954  1.1407  0.7346 -0.4659 -0.5343\n",
            "-0.2113 -0.5192 -0.1990 -0.6047 -0.5659 -0.2850  0.3466 0.6724  0.0553 -0.8608  0.9958  0.3604 -0.6753 -1.4718  0.5628 -1.3841  0.9575  0.7346 -0.4659 -0.5343\n",
            "\n",
            "--- Step 3.5: VariableNumFeaturesEncoderStep ---\n",
            "  Description: Encoder step to handle variable number of features\n",
            "  - This step adds further meta-features after normalization, providing additional context derived from the transformed data.\n",
            "\n",
            "--- Step 3.6: LinearInputEncoderStep ---\n",
            "  Description: A simple linear input encoder step\n",
            "  - This step applies a linear transformation to map the processed feature groups into a higher-dimensional embedding space.\n",
            "  - `in_features`: 4 (Input dimension: Size of feature group after previous steps.)\n",
            "  - `out_features`: 192 (Output dimension: Dimensionality of the learned embedding.)\n",
            "  - `weight` shape: torch.Size([192, 4]) (Learned weights matrix.)\n",
            "\n",
            "STEP 3.6 Output (Linear Embedding)\n",
            "   Shape: torch.Size([801, 10, 192]) (Seq, Groups, Dim)\n",
            "   Flattened View: torch.Size([801, 1920]) (Seq, Total_Embedding_Size)\n",
            "   Preview (First 8 dims of Group 0):\n",
            "  Dim_0   Dim_1   Dim_2   Dim_3   Dim_4   Dim_5   Dim_6   Dim_7\n",
            " 0.8891 -0.0054  0.2727 -0.2956  0.8948  0.2139 -0.1209  0.9671\n",
            "-1.7054 -0.0206 -0.0240  1.0353 -0.6884 -2.2213  0.6775 -0.0468\n",
            " 0.7185 -0.3611  0.2722 -0.8858  0.9146  1.5435  0.1677  0.9069\n",
            " 0.7648 -0.2644  0.2723 -0.7254  0.9092  1.1822  0.0893  0.9233\n",
            " 0.7494 -0.2966  0.2723 -0.7788  0.9110  1.3026  0.1154  0.9178\n",
            "   ... (+ 1912 more columns) ...\n"
          ]
        }
      ],
      "source": [
        "# @title Steps 3.1-3.6: Encoder Pipeline Walkthrough\n",
        "# Initial input before encoder steps\n",
        "view_tensor(X_flat, \"RAW INPUT: X_flat\")\n",
        "\n",
        "# --- Step 3.1: NanHandlingEncoderStep (Remove Empty Features) ---\n",
        "step_empty = model.encoder[0]\n",
        "print(f\"\\n--- Step 3.1: {step_empty.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_empty.__doc__.strip().split('.')[0].strip() if step_empty.__doc__ else 'No description available.'}\")\n",
        "out_dict_step_3_1 = step_empty({\"main\": X_flat}, single_eval_pos=single_eval_pos)\n",
        "view_tensor(out_dict_step_3_1[\"main\"], \"STEP 3.1 Output (Remove Empty Features)\")\n",
        "\n",
        "# --- Step 3.2: NanHandlingEncoderStep (NaN Handling) ---\n",
        "step_nan = model.encoder[1]\n",
        "print(f\"\\n--- Step 3.2: {step_nan.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_nan.__doc__.strip().split('.')[0].strip() if step_nan.__doc__ else 'No description available.'}\")\n",
        "print(f\"  - `keep_nans`: {step_nan.keep_nans} (If True, adds separate indicator columns for NaNs/Infs)\")\n",
        "out_dict_step_3_2 = step_nan(out_dict_step_3_1, single_eval_pos=single_eval_pos)\n",
        "view_tensor(out_dict_step_3_2[\"main\"], \"STEP 3.2 Output (NaN Handling)\")\n",
        "\n",
        "# --- Step 3.3: MetaFeaturesEncoderStep (Meta-feature generation) ---\n",
        "step_meta1 = model.encoder[2]\n",
        "print(f\"\\n--- Step 3.3: {step_meta1.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_meta1.__doc__.strip().split('.')[0].strip() if step_meta1.__doc__ else 'No description available.'}\")\n",
        "print(f\"  - This step typically adds meta-features, such as indicators for original NaN positions, to provide more context to the model.\")\n",
        "out_dict_step_3_3 = step_meta1(out_dict_step_3_2, single_eval_pos=single_eval_pos)\n",
        "\n",
        "# --- Step 3.4: InputNormalizationEncoderStep (Normalization) ---\n",
        "step_norm = model.encoder[3]\n",
        "print(f\"\\n--- Step 3.4: {step_norm.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_norm.__doc__.strip().split('.')[0].strip() if step_norm.__doc__ else 'No description available.'}\")\n",
        "print(f\"  - This step normalizes features to a standard scale (e.g., mean 0, variance 1).\")\n",
        "\n",
        "# Corrected attributes for v2\n",
        "print(f\"  - `normalize_x`: {step_norm.normalize_x} (If True, performs standard mean/std normalization.)\")\n",
        "print(f\"  - `remove_outliers`: {step_norm.remove_outliers} (If True, outliers are clipped based on sigma.)\")\n",
        "if step_norm.remove_outliers:\n",
        "    print(f\"  - `remove_outliers_sigma`: {step_norm.remove_outliers_sigma}\")\n",
        "\n",
        "# Corrected buffer names for statistics\n",
        "if hasattr(step_norm, 'mean_for_normalization') and step_norm.mean_for_normalization is not None:\n",
        "    # Detach and flatten for clean printing\n",
        "    mean_val = step_norm.mean_for_normalization.detach().cpu().numpy().flatten()\n",
        "    print(f\"  - `mean` (first 5 values): {mean_val[:5]} (Learned means.)\")\n",
        "\n",
        "if hasattr(step_norm, 'std_for_normalization') and step_norm.std_for_normalization is not None:\n",
        "    std_val = step_norm.std_for_normalization.detach().cpu().numpy().flatten()\n",
        "    print(f\"  - `std` (first 5 values): {std_val[:5]} (Learned standard deviations.)\")\n",
        "out_dict_step_3_4 = step_norm(out_dict_step_3_3, single_eval_pos=single_eval_pos)\n",
        "view_tensor(out_dict_step_3_4[\"main\"], \"STEP 3.4 Output (Normalization)\")\n",
        "\n",
        "# --- Step 3.5: MetaFeaturesEncoderStep (Meta-feature generation) ---\n",
        "step_meta2 = model.encoder[4]\n",
        "print(f\"\\n--- Step 3.5: {step_meta2.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_meta2.__doc__.strip().split('.')[0].strip() if step_meta2.__doc__ else 'No description available.'}\")\n",
        "print(f\"  - This step adds further meta-features after normalization, providing additional context derived from the transformed data.\")\n",
        "out_dict_step_3_5 = step_meta2(out_dict_step_3_4, single_eval_pos=single_eval_pos)\n",
        "\n",
        "# --- Step 3.6: LinearEncoderStep (Linear Embedding) ---\n",
        "step_embedding = model.encoder[5]\n",
        "print(f\"\\n--- Step 3.6: {step_embedding.__class__.__name__} ---\")\n",
        "print(f\"  Description: {step_embedding.__doc__.strip().split('.')[0].strip() if step_embedding.__doc__ else 'No description available.'}\")\n",
        "print(f\"  - This step applies a linear transformation to map the processed feature groups into a higher-dimensional embedding space.\")\n",
        "\n",
        "# [CHANGE] Access attributes via .layer\n",
        "print(f\"  - `in_features`: {step_embedding.layer.in_features} (Input dimension: Size of feature group + NaN indicators [2+2])\")\n",
        "print(f\"  - `out_features`: {step_embedding.layer.out_features} (Output dimension: Dimensionality of the learned embedding.)\")\n",
        "print(f\"  - `weight` shape: {step_embedding.layer.weight.shape} (Learned weights matrix.)\")\n",
        "\n",
        "if step_embedding.layer.bias is not None:\n",
        "    print(f\"  - `bias` shape: {step_embedding.layer.bias.shape} (Learned bias vector.)\")\n",
        "\n",
        "out_dict_step_3_6 = step_embedding(out_dict_step_3_5, single_eval_pos=single_eval_pos)\n",
        "view_embedding(out_dict_step_3_6[\"output\"], \"STEP 3.6 Output (Linear Embedding)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFO2brhgyxbj",
        "outputId": "138441f2-8d5f-4395-e7fa-9cd78719c9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_embedded.shape=torch.Size([801, 10, 192])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{X_embedded.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oviUfRWp5sw3",
        "outputId": "ce2a2508-a720-406b-ad64-b5feb3d0bb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RAW INPUT: X_flat\n",
            "   Shape: torch.Size([801, 10, 2])\n",
            "   View:  (Showing 5 rows x 20 cols)\n",
            "     0       1      2      3      4      5       6      7        8      9       10       11     12      13     14       15      16     17     18     19\n",
            " 3.7606     NaN 8.2046 1.0000 0.9873 0.1329 16.0000 0.5575 620.0000 0.0000  1.1015 136.0000 0.8038 -0.2178 2.0000 227.0000 -0.7573 1.0000    NaN 3.0000\n",
            " 1.4647 57.9792 3.7324 0.0000 0.8228 0.1329 16.0000 0.8695   7.0000 2.0000 -2.5159  16.0000 0.0000  0.9315 0.0000 325.0000  0.9160 0.0000 0.5327 1.0000\n",
            "-1.0227     NaN 8.0700 0.0000 0.0000    NaN     NaN 0.8100 433.0000 0.0000  0.9664 136.0000 0.0000  1.0247 1.0000 642.0000  0.7548 1.0000    NaN 0.0000\n",
            "-0.0930     NaN 7.0441 0.0000 0.0000 0.1519 17.0000 0.7892 248.0000 0.0000  1.6840 136.0000 0.0000 -1.3137 2.0000 164.0000  1.2673 1.0000    NaN 0.0000\n",
            "-0.3417     NaN 7.1577 0.0000 0.0000 0.2722 21.0000 0.6737 239.0000 0.0000  1.4180 136.0000 0.0000 -1.5731 2.0000  75.0000  0.9931 1.0000    NaN 0.0000\n",
            "\n",
            "STEP 3.5: LINEAR EMBEDDING\n",
            "   Shape: torch.Size([801, 10, 192]) (Seq, Groups, Dim)\n",
            "   Flattened View: torch.Size([801, 1920]) (Seq, Total_Embedding_Size)\n",
            "   Preview (First 8 dims of Group 0):\n",
            "  Dim_0   Dim_1   Dim_2   Dim_3   Dim_4   Dim_5   Dim_6   Dim_7\n",
            " 0.8891 -0.0054  0.2727 -0.2956  0.8948  0.2139 -0.1209  0.9671\n",
            "-1.7054 -0.0206 -0.0240  1.0353 -0.6884 -2.2213  0.6775 -0.0468\n",
            " 0.7185 -0.3611  0.2722 -0.8858  0.9146  1.5435  0.1677  0.9069\n",
            " 0.7648 -0.2644  0.2723 -0.7254  0.9092  1.1822  0.0893  0.9233\n",
            " 0.7494 -0.2966  0.2723 -0.7788  0.9110  1.3026  0.1154  0.9178\n",
            "   ... (+ 1912 more columns) ...\n"
          ]
        }
      ],
      "source": [
        "# @title Run the full encoder\n",
        "# We use the internal method to reproduce the preprocessing exactly\n",
        "# This returns the numpy array that TabPFN actually uses\n",
        "\n",
        "view_tensor(X_flat, \"RAW INPUT: X_flat\")\n",
        "X_embedded = model.encoder({\"main\": X_flat}, single_eval_pos=0)\n",
        "view_embedding(X_embedded, \"STEP 3.5: LINEAR EMBEDDING\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show Steps for a single row\n",
        "curr_i = 0\n",
        "\n",
        "row_raw = X_raw.iloc[[0]].copy()\n",
        "print(f\"=== STEP 0: RAW DATA ===\")\n",
        "print(row_raw.T)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "ensemble_configs, X_processed, y_processed = clf._initialize_dataset_preprocessing(X_raw, y_raw, rng=42)\n",
        "row_step1 = X_processed[0]\n",
        "\n",
        "print(f\"=== STEP 1: GLOBAL PREPROCESSING OUTPUT ===\")\n",
        "print(f\"Shape: {X_processed.shape}\")\n",
        "print(f\"Data Type: {X_processed.dtype}\")\n",
        "print(f\"Content (Float Matrix):\\n{np.round(row_step1, 3)}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "input_cat_cols = clf.preprocessor_.transformers_[0][2]\n",
        "cat_ix = list(range(len(input_cat_cols)))\n",
        "view_num = 0\n",
        "curr_config = ensemble_configs[view_num]\n",
        "curr_pipeline = curr_config.to_pipeline(random_state=42)\n",
        "res = curr_pipeline.fit_transform(X_processed, cat_ix)\n",
        "X_view = res.X\n",
        "row_step2 = X_view[0]\n",
        "\n",
        "print(f\"=== STEP 2: ENSEMBLE VIEW #0 OUTPUT ===\")\n",
        "print(f\"Shape: {X_view.shape} (Notice extra fingerprint and transformation columns are added)\")\n",
        "print(f\"Content (Randomized & Scaled):\\n{np.round(row_step2, 3)}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "row_step3_start = X_flat[0]\n",
        "print(f\"=== STEP 3: LATENT EMBEDDING (Thinking Token) ===\")\n",
        "print(f\"\\n--- Start: from vector to tensor ---\")\n",
        "print(f\"Shape: {X_flat.shape}\")\n",
        "print(f\"Content (Tensor):\\n{np.round(row_step3_start, 3)}\")\n",
        "\n",
        "\n",
        "X_embedded = model.encoder({\"main\": X_flat}, single_eval_pos=0)\n",
        "row_step3_end = X_embedded[0]\n",
        "\n",
        "print(f\"\\n--- End: output of linear projection MLP ---\")\n",
        "print(f\"Shape: {X_embedded.shape}\")\n",
        "print(f\"Content (First 8 Embedding Dims):\\n{np.round(row_step3_end[:,:8].detach().numpy(), 3)} ...\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgOTnGaMKXG6",
        "outputId": "2d053db5-0395-4993-bcbd-27f2e4609085"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STEP 0: RAW DATA ===\n",
            "                              86\n",
            "Pclass                         3\n",
            "Sex                         male\n",
            "Age                         16.0\n",
            "SibSp                          1\n",
            "Parch                          3\n",
            "Fare                      34.375\n",
            "Embarked                       S\n",
            "Ticket                W./C. 6608\n",
            "Name      Ford, Mr. William Neal\n",
            "Cabin                        NaN\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== STEP 1: GLOBAL PREPROCESSING OUTPUT ===\n",
            "Shape: (801, 10)\n",
            "Data Type: float64\n",
            "Content (Float Matrix):\n",
            "[  2.   1.   2. 620. 227. 136.  16.   1.   3.  nan]\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== STEP 2: ENSEMBLE VIEW #0 OUTPUT ===\n",
            "Shape: (801, 20) (Notice extra fingerprint and transformation columns are added)\n",
            "Content (Randomized & Scaled):\n",
            "[  3.761     nan   8.205   1.      0.987   0.133  16.      0.557 620.\n",
            "   0.      1.102 136.      0.804  -0.218   2.    227.     -0.757   1.\n",
            "     nan   3.   ]\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== STEP 3: LATENT EMBEDDING (Thinking Token) ===\n",
            "\n",
            "--- Start: from vector to tensor ---\n",
            "Shape: torch.Size([801, 10, 2])\n",
            "Content (Tensor):\n",
            "tensor([[  3.7610,      nan],\n",
            "        [  8.2050,   1.0000],\n",
            "        [  0.9870,   0.1330],\n",
            "        [ 16.0000,   0.5570],\n",
            "        [620.0000,   0.0000],\n",
            "        [  1.1020, 136.0000],\n",
            "        [  0.8040,  -0.2180],\n",
            "        [  2.0000, 227.0000],\n",
            "        [ -0.7570,   1.0000],\n",
            "        [     nan,   3.0000]])\n",
            "\n",
            "--- End: output of linear projection MLP ---\n",
            "Shape: torch.Size([801, 10, 192])\n",
            "Content (First 8 Embedding Dims):\n",
            "[[ 0.889 -0.005  0.273 -0.296  0.895  0.214 -0.121  0.967]\n",
            " [-0.814 -0.002 -0.012  0.509 -0.331 -1.094  0.319 -0.021]\n",
            " [ 0.872  0.345  0.01   0.128  0.268 -0.334 -0.555  0.077]\n",
            " [-0.295 -0.008 -0.004  0.171 -0.118 -0.366  0.12  -0.009]\n",
            " [ 0.886  0.217  0.011 -0.134  0.306  0.251 -0.481  0.057]\n",
            " [-0.29   0.078 -0.005  0.336 -0.138 -0.736  0.064  0.005]\n",
            " [ 0.38   0.221  0.004  0.194  0.099 -0.455 -0.286  0.044]\n",
            " [ 0.292  0.103  0.004  0.018  0.093 -0.057 -0.178  0.024]\n",
            " [-0.756 -0.184 -0.01   0.116 -0.261 -0.217  0.41  -0.048]\n",
            " [-3.22   0.428 -0.744  0.224 -0.313 -2.307  0.589 -1.028]] ...\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py:566: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
            "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
            "  X_raw: single or list of input dataset features, in case of single it\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPCrPmhRnLby7qydsajI5ET",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0957dadd37824a0f9b9adf623e72c505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_363b55b04f184a02aa5e8e3b5b01abd0",
              "IPY_MODEL_877ff8b187ba48538cb881aa0b00039b",
              "IPY_MODEL_4f64dda473ec4303b6f5025164cdb9a4"
            ],
            "layout": "IPY_MODEL_be29304e7da547f9b7c38eab1df3e07b"
          }
        },
        "363b55b04f184a02aa5e8e3b5b01abd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311f2e6e9c1e4ecb858c3fe80b778153",
            "placeholder": "​",
            "style": "IPY_MODEL_484872c0132c4cb58fbea0d3756f8464",
            "value": "tabpfn-v2-classifier-finetuned-zk73skhh.(…): 100%"
          }
        },
        "877ff8b187ba48538cb881aa0b00039b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da5a8773e0243e287005b9ae37e16af",
            "max": 29009539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f787781975464c40b60ca250cab3a416",
            "value": 29009539
          }
        },
        "4f64dda473ec4303b6f5025164cdb9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10c62c1a2bf4691bcc651b07386b32c",
            "placeholder": "​",
            "style": "IPY_MODEL_2681578b0f7b4b97b4b56298d544a5a3",
            "value": " 29.0M/29.0M [00:01&lt;00:00, 20.4MB/s]"
          }
        },
        "be29304e7da547f9b7c38eab1df3e07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311f2e6e9c1e4ecb858c3fe80b778153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484872c0132c4cb58fbea0d3756f8464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9da5a8773e0243e287005b9ae37e16af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f787781975464c40b60ca250cab3a416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a10c62c1a2bf4691bcc651b07386b32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2681578b0f7b4b97b4b56298d544a5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab1b780b8b546ef8a110cbb00af71a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29048f9d63344e51b60d94e8db67fdf0",
              "IPY_MODEL_621d9ccff5d6484f9170b97395f68df9",
              "IPY_MODEL_f4c646118a3944c3a5d09a5aaea0f965"
            ],
            "layout": "IPY_MODEL_5e3953ee49fc43ed85a6b77ef52844fa"
          }
        },
        "29048f9d63344e51b60d94e8db67fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_badbbe9d88b942bd9263bfbb7fa527c3",
            "placeholder": "​",
            "style": "IPY_MODEL_a157b69dd96a4728918e38feeaa77fb9",
            "value": "config.json: 100%"
          }
        },
        "621d9ccff5d6484f9170b97395f68df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6bfbc483974cc0816b3ec46fc166c0",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7af7bb1d02df42e89a9bdce10a8baa1c",
            "value": 37
          }
        },
        "f4c646118a3944c3a5d09a5aaea0f965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60623e4ce60e4b6eaa555650ff4b8d90",
            "placeholder": "​",
            "style": "IPY_MODEL_9baf3a28031c4c47bd77f0fe88e1f24c",
            "value": " 37.0/37.0 [00:00&lt;00:00, 2.30kB/s]"
          }
        },
        "5e3953ee49fc43ed85a6b77ef52844fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "badbbe9d88b942bd9263bfbb7fa527c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a157b69dd96a4728918e38feeaa77fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a6bfbc483974cc0816b3ec46fc166c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af7bb1d02df42e89a9bdce10a8baa1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60623e4ce60e4b6eaa555650ff4b8d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9baf3a28031c4c47bd77f0fe88e1f24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}